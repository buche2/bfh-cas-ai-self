{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcrCNS6jc5-e"
   },
   "source": [
    "## Lenet-5 Inspired Network in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dieser Code wurde aus einem shallow zu einem dense network in ein CNN gewandelt. Daher sind teilweise die variabeln nicht angepasst (z.B. X_flat)."
   ],
   "metadata": {
    "id": "0qLHFUq9pVoN"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEygUgLVKJ7x"
   },
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nfFVh41odSXB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-summary in c:\\users\\enrico\\pycharmprojects\\bfh-ai-1\\venv\\lib\\site-packages (1.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Enrico\\PycharmProjects\\bfh-ai-1\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QCoX-S6dj54"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UXk2_Pazef4W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9912422 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f73d58eb11f54404a532c1631544ffb5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/28881 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a980a5b229194793bcc0ecf1dcbab767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1648877 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75e77521dccc4f5f94421365059dcad9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4542 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e46e3bebe6544918617b588ad286b87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = MNIST('data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test = MNIST('data', train=False, transform=transforms.ToTensor())\n",
    "# ...toTensor() scales pixels from [0, 255] to [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYMXOGJvfkCo"
   },
   "source": [
    "#### Batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8IySNK8Ef6Eq"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128) \n",
    "# ...DataLoader() can also sample and run multithreaded over a set number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SLfWTrjshEsh"
   },
   "outputs": [],
   "source": [
    "X_sample, y_sample = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zlj29yCske1c"
   },
   "outputs": [],
   "source": [
    "X_flat_sample_flat = X_sample.view(X_sample.shape[0], -1) # view() reshapes Tensor (confusingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VtnEEvLi4UD",
    "outputId": "138c86c3-2b0b-473d-9dda-4b84691f12b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 784])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_sample_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_flat_sample_2d = X_sample.view(X_sample.shape[0], 1, 28, 28) # view() reshapes Tensor (confusingly)"
   ],
   "metadata": {
    "id": "YWv-PvWmljC_"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Syt9nxPHljww",
    "outputId": "633a91ab-369c-427e-fef2-aa5a73cecd56",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 1, 28, 28])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_sample_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Koet4ZSgkSHu",
    "outputId": "ee43c968-b5bd-47f4-f6fa-cf0d95612f63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0078, 0.4745, 0.9961, 0.9961, 0.3059,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.3490, 0.9922, 0.8000, 0.7333, 0.9569,\n          0.3255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.4784, 0.8510, 0.0471, 0.0000, 0.6392,\n          0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.4784, 0.8196, 0.0000, 0.0000, 0.5647,\n          0.9843, 0.2039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.4784, 0.8196, 0.0000, 0.0000, 0.5647,\n          0.9922, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.4784, 0.8196, 0.0000, 0.0000, 0.7137,\n          0.9922, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0588, 0.7725, 0.7765, 0.8549, 0.9961,\n          0.9922, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.7059, 0.9725, 0.9961,\n          0.9922, 0.5255, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 1.0000,\n          0.9137, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5686, 0.9961,\n          0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.8863, 0.9843,\n          0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.6745, 0.9922, 0.5647,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.1176, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0196, 0.4980, 0.9922, 0.8235, 0.2667,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4235,\n          0.5373, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0902, 0.2588,\n          0.4863, 0.0902, 0.0902, 0.6941, 0.9922, 0.9686, 0.1333, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1294, 0.8706,\n          0.3333, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2275, 0.9922, 0.9922,\n          0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.3529, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.8588, 0.7961,\n          0.0471, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.8902, 0.9922,\n          0.9922, 0.9922, 0.9922, 0.9922, 0.8196, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.3529,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.2549,\n          0.2902, 0.0863, 0.0863, 0.3137, 0.9608, 0.7765, 0.0627, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0314, 0.5333, 0.9843, 0.8000, 0.0235,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.3451, 0.9922, 0.6549, 0.3647,\n          0.1765, 0.1765, 0.4039, 0.8588, 0.9922, 0.9490, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.3922, 0.9569, 0.9961,\n          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.4980, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.5608,\n          0.8627, 0.9922, 0.9569, 0.5608, 0.2196, 0.0118, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000, 0.0000, 0.0000]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flat_sample_2d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-lTFFhdkogC"
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XLAYTQcrk208",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "outputId": "a37a60d9-7341-4642-b4d1-715ce5c8f6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# build our deep nn model\\nmodel = nn.Sequential( # attention! Use of Brackets! > meaning each line ends with a comma\\n    \\n     ### hidden layer 1     \\n    # Input channels = 1, output channels = 32\\n    torch.nn.Conv2d(1, 32, kernel_size=(5,5)), # 32 unique patterns of simple line orientations\\n    nn.ReLU(),\\n\\n    ### hidden layer 2\\n    # Input channels = 32. output channels = 64\\n    torch.nn.Conv2d(32, 64, kernel_size= (5,5)), # 64 non linear recombinations of the 32 input features\\n    nn.ReLU(),\\n    \\n    ### pooling Layer\\n    nn.MaxPool2d((2,2)), # downsampling > discards 50% of the activations\\n\\n#        self.pool = torch.nn.MaxPool2d((2,2), stride=2) # downsampling > discards exactly 75% of the activations\\n        \\n    ### dropout Layer\\n    nn.Dropout2d(0.3), # help to generalize for unseen data\\n\\n    ### flatten Layer\\n    nn.Flatten(), # reduce dimensions\\n\\n    ### hidden Layer 3\\n    nn.Linear(64 * 10 * 10, 128), # transform\\n    nn.ReLU(),\\n    \\n    ### dropout Layer\\n    nn.Dropout(0.5), # help to generalize for unseen data\\n\\n    ### output Layer\\n    # input features = 128. output features = 10 for our 10 defined classes\\n    nn.Linear(128, 10),\\n    nn.ReLU(),\\n\\n)\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# build our deep nn model\n",
    "model = nn.Sequential( # attention! Use of Brackets! > meaning each line ends with a comma\n",
    "    \n",
    "     ### hidden layer 1     \n",
    "    # Input channels = 1, output channels = 32\n",
    "    torch.nn.Conv2d(1, 32, kernel_size=(5,5)), # 32 unique patterns of simple line orientations\n",
    "    nn.ReLU(),\n",
    "\n",
    "    ### hidden layer 2\n",
    "    # Input channels = 32. output channels = 64\n",
    "    torch.nn.Conv2d(32, 64, kernel_size= (5,5)), # 64 non linear recombinations of the 32 input features\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    ### pooling Layer\n",
    "    nn.MaxPool2d((2,2)), # downsampling > discards 50% of the activations\n",
    "\n",
    "#        self.pool = torch.nn.MaxPool2d((2,2), stride=2) # downsampling > discards exactly 75% of the activations\n",
    "        \n",
    "    ### dropout Layer\n",
    "    nn.Dropout2d(0.3), # help to generalize for unseen data\n",
    "\n",
    "    ### flatten Layer\n",
    "    nn.Flatten(), # reduce dimensions\n",
    "\n",
    "    ### hidden Layer 3\n",
    "    nn.Linear(64 * 10 * 10, 128), # transform\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    ### dropout Layer\n",
    "    nn.Dropout(0.5), # help to generalize for unseen data\n",
    "\n",
    "    ### output Layer\n",
    "    # input features = 128. output features = 10 for our 10 defined classes\n",
    "    nn.Linear(128, 10),\n",
    "    nn.ReLU(),\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NDOFB3RWquQ4"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.flatten import Flatten\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "\n",
    "# build our deep nn model\n",
    "model = nn.Sequential(\n",
    "    \n",
    "    nn.Conv2d(1, 6, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    \n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(256, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.25),\n",
    "\n",
    "    nn.Linear(120, 84),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "\n",
    "    nn.Linear(84, 10),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELhOOEzcmMjN",
    "outputId": "df178248-22ab-4b85-a056-a56f245d3325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 6, 24, 24]           156\n",
      "├─ReLU: 1-2                              [-1, 6, 24, 24]           --\n",
      "├─MaxPool2d: 1-3                         [-1, 6, 12, 12]           --\n",
      "├─Conv2d: 1-4                            [-1, 16, 8, 8]            2,416\n",
      "├─ReLU: 1-5                              [-1, 16, 8, 8]            --\n",
      "├─MaxPool2d: 1-6                         [-1, 16, 4, 4]            --\n",
      "├─Flatten: 1-7                           [-1, 256]                 --\n",
      "├─Linear: 1-8                            [-1, 120]                 30,840\n",
      "├─ReLU: 1-9                              [-1, 120]                 --\n",
      "├─Dropout: 1-10                          [-1, 120]                 --\n",
      "├─Linear: 1-11                           [-1, 84]                  10,164\n",
      "├─ReLU: 1-12                             [-1, 84]                  --\n",
      "├─Dropout: 1-13                          [-1, 84]                  --\n",
      "├─Linear: 1-14                           [-1, 10]                  850\n",
      "==========================================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.28\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 0.21\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Conv2d: 1-1                            [-1, 6, 24, 24]           156\n├─ReLU: 1-2                              [-1, 6, 24, 24]           --\n├─MaxPool2d: 1-3                         [-1, 6, 12, 12]           --\n├─Conv2d: 1-4                            [-1, 16, 8, 8]            2,416\n├─ReLU: 1-5                              [-1, 16, 8, 8]            --\n├─MaxPool2d: 1-6                         [-1, 16, 4, 4]            --\n├─Flatten: 1-7                           [-1, 256]                 --\n├─Linear: 1-8                            [-1, 120]                 30,840\n├─ReLU: 1-9                              [-1, 120]                 --\n├─Dropout: 1-10                          [-1, 120]                 --\n├─Linear: 1-11                           [-1, 84]                  10,164\n├─ReLU: 1-12                             [-1, 84]                  --\n├─Dropout: 1-13                          [-1, 84]                  --\n├─Linear: 1-14                           [-1, 10]                  850\n==========================================================================================\nTotal params: 44,426\nTrainable params: 44,426\nNon-trainable params: 0\nTotal mult-adds (M): 0.28\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.04\nParams size (MB): 0.17\nEstimated Total Size (MB): 0.21\n=========================================================================================="
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad12qUaumQNF"
   },
   "source": [
    "#### Configure training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MApHSXQGmfdE"
   },
   "outputs": [],
   "source": [
    "cost_fxn = nn.CrossEntropyLoss() # includes softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "K0c1Iqnpm32m"
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer = torch.optim.NAdam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3836ImZnQ6_"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "p9iTkEv6nVHB"
   },
   "outputs": [],
   "source": [
    "def accuracy_pct(pred_y, true_y):\n",
    "  _, prediction = torch.max(pred_y, 1) # returns maximum values, indices; fed tensor, dim to reduce\n",
    "  correct = (prediction == true_y).sum().item()\n",
    "  return (correct / true_y.shape[0]) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkd4YuS4xBaF",
    "outputId": "55bce671-ab60-4539-8f39-9d3a86201b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "469"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches = len(train_loader)\n",
    "n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka2rxjOcnY_1",
    "outputId": "87e50800-1669-4255-a5c0-ff1732ab65a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 15 epochs. \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 1/15 complete: Cost: 0.379, Accuracy: 88.4% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 2/15 complete: Cost: 0.119, Accuracy: 96.7% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 3/15 complete: Cost: 0.092, Accuracy: 97.5% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 4/15 complete: Cost: 0.077, Accuracy: 98.0% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 5/15 complete: Cost: 0.063, Accuracy: 98.2% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 6/15 complete: Cost: 0.055, Accuracy: 98.5% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 7/15 complete: Cost: 0.051, Accuracy: 98.5% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 8/15 complete: Cost: 0.046, Accuracy: 98.7% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 9/15 complete: Cost: 0.044, Accuracy: 98.8% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 10/15 complete: Cost: 0.041, Accuracy: 98.9% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 11/15 complete: Cost: 0.038, Accuracy: 98.9% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 12/15 complete: Cost: 0.036, Accuracy: 99.0% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 13/15 complete: Cost: 0.033, Accuracy: 99.1% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 14/15 complete: Cost: 0.033, Accuracy: 99.1% \n",
      "\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "Epoch 15/15 complete: Cost: 0.030, Accuracy: 99.1% \n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "\n",
    "print('Training for {} epochs. \\n'.format(n_epochs))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "  avg_cost = 0.0\n",
    "  avg_accuracy = 0.0\n",
    "  \n",
    "  for i, (X, y) in enumerate(train_loader): # enumerate() provides count of iterations  \n",
    "    \n",
    "    # forward propagation:\n",
    "    # X_flat = X.view(X.shape[0], -1)\n",
    "    X_flat = X.view(X.shape[0], 1, 28, 28)\n",
    "    y_hat = model(X_flat)\n",
    "    cost = cost_fxn(y_hat, y)\n",
    "    avg_cost += cost / n_batches\n",
    "    \n",
    "    # backprop and optimization via gradient descent: \n",
    "    optimizer.zero_grad() # set gradients to zero; .backward() accumulates them in buffers\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # calculate accuracy metric:\n",
    "    accuracy = accuracy_pct(y_hat, y)\n",
    "    avg_accuracy += accuracy / n_batches\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "      print('Step {}'.format(i + 1))\n",
    "    \n",
    "  print('Epoch {}/{} complete: Cost: {:.3f}, Accuracy: {:.1f}% \\n'\n",
    "        .format(epoch + 1, n_epochs, avg_cost, avg_accuracy)) \n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmUI1Z7jj0XO"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "r1-3E_YfkIL7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2a681d6c-7878-4c30-9e6b-23236ea854a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "79"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_batches = len(test_loader)\n",
    "n_test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DPU-rP_7jtk_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eaa07c7f-7eae-4da3-f847-364cde4bdeb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cost: 0.036, Test accuracy: 99.1%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # disables dropout (and batch norm)\n",
    "\n",
    "with torch.no_grad(): # disables autograd, reducing memory consumption\n",
    "  \n",
    "  avg_test_cost = 0.0\n",
    "  avg_test_acc = 0.0\n",
    "  \n",
    "  for X, y in test_loader:\n",
    "    \n",
    "    # make predictions: \n",
    "#    X_flat = X.view(X.shape[0], -1) # transforms to 1 x 784* (*with 28 x 28 pixel images)\n",
    "    X_flat = X.view(X.shape[0], 1, 28, 28)\n",
    "    y_hat = model(X_flat)\n",
    "    \n",
    "    # calculate cost: \n",
    "    cost = cost_fxn(y_hat, y)\n",
    "    avg_test_cost += cost / n_test_batches\n",
    "    \n",
    "    # calculate accuracy:\n",
    "    test_accuracy = accuracy_pct(y_hat, y)\n",
    "    avg_test_acc += test_accuracy / n_test_batches\n",
    "\n",
    "print('Test cost: {:.3f}, Test accuracy: {:.1f}%'.format(avg_test_cost, avg_test_acc))\n",
    "\n",
    "# model.train() # 'undoes' model.eval()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Beispiel_Lenet-5_inspired_CNN_45k-param.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}